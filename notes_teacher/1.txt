1.  Прежде чем строить модели, необходимо внимательно посмотреть на данные: понять, какие признаки представлены в таблице, есть ли пропуски и дисбаланс классов, а также как выглядит целевая переменная.

 

2.  Разбиение данных на обучающую и тестовую выборки нужно делать в самом начале, до EDA и любых преобразований признаков, чтобы избежать утечки информации.

 

3.  При небольшом объеме данных слишком маленький test приводит к нестабильным метрикам, которые сильно зависят от случайного seed. Использование стратифицированного разбиения позволяет сохранить пропорции классов и получить более надежную оценку.

 

4.  Выбросы не всегда являются ошибками измерений, и без предметной экспертизы их агрессивное удаление может быть вредным.

 

5.  Преобразования признаков (логарифмирование, power transform) могут улучшить форму распределений, но не гарантируют роста качества модели.

 

6.  Высокая корреляция между признаками ожидаема для групп, описывающих схожие физические характеристики (например, радиус, периметр и площадь). При этом сама по себе корреляция не является достаточным основанием для удаления признаков.

 

7.  Корреляция признаков с целевой переменной дают лишь общее представление о направлении эффекта, и для более строгих выводов необходимо сравнивать распределения признаков между классами и использовать статистические критерии.

 

8.  Распространенная ошибка – обучение PCA сразу на всех данных. Корректный подход – выполнять fit PCA только на обучающей выборке, а затем применять преобразование к тестовой. PCA можно рассматривать как способ работы с коррелированными признаками и снижения размерности, но при этом теряется интерпретируемость.

 

9.  В качестве базовой модели использовалась логистическая регрессия. Было показано, что даже простая линейная модель показывает высокое качество на данном датасете. Добавление L2-регуляризации делает коэффициенты более устойчивыми, но не всегда приводит к заметному росту метрик.

 

10.  PCA снижает размерность, максимизируя дисперсию признаков и не используя информацию о целевой переменной. PLS является supervised-методом: его компоненты строятся с учётом связи признаков с таргетом, что может быть полезно для задач классификации и регрессии при высокой коррелированности признаков.

 

11.  Ошибочные предсказания часто соответствуют объектам, расположенным близко к границе классов, и их анализ может дать полезную информацию о сложности задачи.

 

12.  GridSearch и Optuna для подбора гиперпараметров. GridSearch подходит для небольших пространств параметров, тогда как Optuna удобнее для более сложных и ресурсоемких задач.

 

13.  Важно: качественный результат в ML чаще достигается не за счет сложных моделей, а благодаря корректной методологии: честному разбиению данных, отсутствию утечек, вдумчивому EDA и осмысленной интерпретации результатов.
